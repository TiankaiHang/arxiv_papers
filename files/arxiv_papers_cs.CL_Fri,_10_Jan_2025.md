| ID | Title | Authors | Summary (zh) | Abstract (en) | Abstract (zh) | 
| --- | --- | --- | --- | --- | --- |
2501.05443	 | A survey of textual cyber abuse detection using cutting-edge language models and large language models	 | Jose A. Diaz-Garcia,Joao Paulo Carvalho	 | 本文全面分析了社交媒体平台上不同形式的在线骚扰，特别关注语言模型如何影响这些骚扰内容的检测与生成，并探讨了其传播机制、心理和社会影响，旨在为在线安全和伦理讨论提供见解。	 | The success of social media platforms has facilitated the emergence of various forms of online abuse within digital communities. This abuse manifests in multiple ways, including hate speech, cyberbullying, emotional abuse, grooming, and sexting. In this paper, we present a comprehensive analysis of the different forms of abuse prevalent in social media, with a particular focus on how emerging technologies, such as Language Models (LMs) and Large Language Models (LLMs), are reshaping both the detection and generation of abusive content within these networks. We delve into the mechanisms through which social media abuse is perpetuated, exploring the psychological and social impact. Additionally, we examine the dual role of advanced language models-highlighting their potential to enhance automated detection systems for abusive behavior while also acknowledging their capacity to generate harmful content. This paper aims to contribute to the ongoing discourse on online safety and ethics, offering insights into the evolving landscape of cyberabuse and the technological innovations that both mitigate and exacerbate it.	 | 社交媒体平台的成功为数字社区内的各种形式的在线骚扰提供了滋生的条件。这种骚扰以多种方式表现出来，包括仇恨言论、网络欺凌、情感虐待、诱骗和裸聊。在本文中，我们对社交媒体上存在的不同形式的骚扰进行了全面分析，特别关注新兴技术，如语言模型（LMs）和大型语言模型（LLMs）如何塑造这些网络中的骚扰内容的检测与生成。我们探讨了社交媒体骚扰是如何传播的机制，研究了其心理和社会影响。此外，我们还考察了先进语言模型的双重角色——不仅强调其增强自动化检测系统以识别不良行为的潜力，同时也承认其生成有害内容的能力。本文旨在为在线安全和伦理的持续讨论做出贡献，提供有关不断演变的网络骚扰景观以及既减轻又加剧这种现象的技术创新的见解。
2501.05414	 | LongProc: Benchmarking Long-Context Language Models on Long Procedural Generation	 | Xi Ye,Fangcong Yin,Yinghui He,Joie Zhang,Howard Yen,Tianyu Gao,Greg Durrett,Danqi Chen	 | LongProc 是一个新基准，旨在通过六个多样化任务测试语言模型在长形式生成和综合分散信息方面的能力，挑战现有的长上下文语言模型（LCLMs）；研究发现，尽管大多数模型声称支持大上下文窗口，但在长生成任务中表现不佳，特别是在保持长距离连贯性方面存在明显困难。	 | Existing benchmarks for evaluating long-context language models (LCLMs) primarily focus on long-context recall, requiring models to produce short responses based on a few critical snippets while processing thousands of irrelevant tokens. We introduce LongProc (Long Procedural Generation), a new benchmark that requires both the integration of highly dispersed information and long-form generation. LongProc consists of six diverse procedural generation tasks, such as extracting structured information from HTML pages into a TSV format and executing complex search procedures to create travel plans. These tasks challenge LCLMs by testing their ability to follow detailed procedural instructions, synthesize and reason over dispersed information, and generate structured, long-form outputs (up to 8K tokens). Furthermore, as these tasks adhere to deterministic procedures and yield structured outputs, they enable reliable rule-based evaluation. We evaluate 17 LCLMs on LongProc across three difficulty levels, with maximum numbers of output tokens set at 500, 2K, and 8K. Notably, while all tested models claim a context window size above 32K tokens, open-weight models typically falter on 2K-token tasks, and closed-source models like GPT-4o show significant degradation on 8K-token tasks. Further analysis reveals that LCLMs struggle to maintain long-range coherence in long-form generations. These findings highlight critical limitations in current LCLMs and suggest substantial room for improvement. Data and code available at: https://princeton-pli.github.io/LongProc	 | 现有的长上下文语言模型（LCLMs）评估基准主要关注长上下文的召回率，要求模型基于少数关键片段生成简短响应，同时处理数千个无关的令牌。我们引入了LongProc（长过程生成）这一新基准，它不仅要求模型整合高度分散的信息，还要进行长形式的生成。LongProc 包含六个多样化的过程生成任务，例如将HTML页面中的结构化信息提取到TSV格式，以及执行复杂的搜索程序以创建旅行计划。这些任务通过测试模型遵循详细的程序指令、综合和处理分散的信息、生成结构化、长形式输出（最多8K令牌）的能力，挑战了LCLMs。此外，由于这些任务遵循确定性的程序并产生结构化的输出，它们可以实现可靠的基于规则的评估。我们对17个LCLMs在不同难度级别的LongProc上进行了评估，最大输出令牌数分别设为500、2K和8K。值得注意的是，虽然所有测试模型都声称上下文窗口大小超过32K令牌，但开放式模型通常在2K令牌任务上表现不佳，而封闭源模型如GPT-4o在8K令牌任务上显示出显著的退化。进一步分析表明，LCLMs在长形式生成中难以保持长距离连贯性。这些发现指出了当前LCLMs的关键局限性，并表明有很大改进的空间。数据和代码可在以下网址获取：https://princeton-pli.github.io/LongProc
2501.05396	 | FairCode: Evaluating Social Bias of LLMs in Code Generation	 | Yongkang Du,Jen-tse Huang,Jieyu Zhao,Lu Lin	 | 本文介绍了FairCode，一个用于评估大型语言模型在代码生成中偏见的新基准，包含函数实现和测试案例生成两项任务，并提出FairScore作为评估指标；研究发现所有测试的LLMs均存在不同程度的偏见。	 | Large language models (LLMs) have demonstrated significant capability in code generation, drawing increasing attention to the evaluation of the quality and safety of their outputs. However, research on bias in code generation remains limited. Existing studies typically assess bias by applying malicious prompts or reapply tasks and dataset for discriminative models. Given that LLMs are often aligned with human values and that prior datasets are not fully optimized for code-related tasks, there is a pressing need for benchmarks specifically designed for evaluating code models. In this study, we introduce FairCode, a novel benchmark for evaluating bias in code generation. FairCode comprises two tasks: function implementation and test case generation, each evaluating social bias through diverse scenarios. Additionally, we propose a new metric, FairScore, to assess model performance on this benchmark. We conduct experiments on widely used LLMs and provide a comprehensive analysis of the results. The findings reveal that all tested LLMs exhibit bias. The code is available at https://github.com/YongkDu/FairCode.	 | 大型语言模型（LLMs）在代码生成方面展现了显著的能力，这引起了对它们输出的质量和安全性的评估日益增加的关注。然而，关于代码生成中的偏见研究仍然有限。现有的研究通常通过应用恶意提示或重新应用任务和数据集来评估偏见，这种方法主要针对区分模型。鉴于LLMs往往与人类价值观对齐，并且先前的数据集在代码相关任务方面并未完全优化，因此特别设计用于评估代码模型的基准显得尤为迫切。在本研究中，我们引入了一个名为FairCode的新基准，用于评估代码生成中的偏见。FairCode包含两项任务：函数实现和测试案例生成，每项任务通过不同的场景评估社会偏见。此外，我们提出了一种新的评估指标FairScore，用于评估模型在该基准上的表现。我们在广泛使用的LLMs上进行了实验，并对结果进行了全面分析。研究结果表明，所有测试的LLMs都存在偏见。代码可在https://github.com/YongkDu/FairCode获取。
2501.05336	 | Stream Aligner: Efficient Sentence-Level Alignment via Distribution Induction	 | Hantao Lou,Jiaming Ji,Kaile Wang,Yaodong Yang	 | 本文提出了一种名为流式对齐器（Stream Aligner）的新颖对齐范式，通过动态纠正模型生成的句子来增强LLMs的性能，减少对额外模型能力的依赖并降低用户交互延迟，实验表明该方法在提升模型的帮助性和无害性以及增强数学能力方面效果显著。	 | The rapid advancement of large language models (LLMs) has led to significant improvements in their capabilities, but also to increased concerns about their alignment with human values and intentions. Current alignment strategies, including adaptive training and inference-time methods, have demonstrated potential in this area. However, these approaches still struggle to balance deployment complexity and capability across various tasks and difficulties. In this work, we introduce the Streaming Distribution Induce Aligner (Stream Aligner), a novel alignment paradigm that combines efficiency with enhanced performance in various tasks throughout the generation process. Stream Aligner achieves dynamic sentence-level correction by using a small model to learn the preferences of the suffix sentence, iteratively correcting the suffix sentence output by the upstream model, and then using the corrected sentence to replace the suffix sentence in subsequent generations. Compared to Aligner, our experiments demonstrate that Stream Aligner reduces reliance on the capabilities of additional models, enhances the reasoning abilities of LLMs, and decreases latency during user interaction. Specifically, Stream Aligner-2B model has achieved an improvement of 76.1% in helpfulness, 36.0% in harmlessness on the tested Llama2-70B-chat model, and Stream Aligner-8B has achieved an improvement of 3.5% on the math ability of the tested Llama3-70B-Instruct model.	 | 随着大型语言模型（LLMs）的迅猛发展，它们的能力得到了显著提升，但也引发了人们对这些模型与人类价值观和意图是否一致的关注增加。当前的对齐策略，包括自适应训练和推理时的方法，已经在这一领域展现了潜力。然而，这些方法在平衡部署复杂性和各种任务和困难的能力方面仍然存在问题。在本文中，我们提出了 Streaming Distribution Induce Aligner（流式对齐器，简称Stream Aligner），这是一种结合了高效性和在生成过程中各种任务上的增强性能的新颖对齐范式。流式对齐器通过使用一个小模型学习后缀句子的偏好，并迭代地纠正上游模型输出的后缀句子，然后用纠正过的句子替换后续生成中的后缀句子，实现了动态的句子级纠正。与Aligner相比，我们的实验表明，流式对齐器减少了对额外模型能力的依赖，增强了LLM的推理能力，并降低了用户交互过程中的延迟。具体而言，流式对齐器-2B模型在测试的Llama2-70B-chat模型上实现了76.1%的帮助性提升和36.0%的无害性提升，而流式对齐器-8B模型在测试的Llama3-70B-Instruct模型上实现了3.5%的数学能力提升。
2501.05260	 | Enhancing Plagiarism Detection in Marathi with a Weighted Ensemble of TF-IDF and BERT Embeddings for Low-Resource Language Processing	 | Atharva Mutsaddi,Aditya Choudhary	 | 本文提出了一种结合BERT句向量表示和TF-IDF特征表示的方法，用于提高马哈拉施特拉语文本原创性检测的准确性，并通过加权投票集成的机器学习模型有效捕捉文本的统计、语义和句法特征。随着低资源语言数据的增加，设计适合这些语言的robust原创性检测系统显得尤为重要。	 | Plagiarism involves using another person's work or concepts without proper attribution, presenting them as original creations. With the growing amount of data communicated in regional languages such as Marathi -- one of India's regional languages -- it is crucial to design robust plagiarism detection systems tailored for low-resource languages. Language models like Bidirectional Encoder Representations from Transformers (BERT) have demonstrated exceptional capability in text representation and feature extraction, making them essential tools for semantic analysis and plagiarism detection. However, the application of BERT for low-resource languages remains under-explored, particularly in the context of plagiarism detection. This paper presents a method to enhance the accuracy of plagiarism detection for Marathi texts using BERT sentence embeddings in conjunction with Term Frequency-Inverse Document Frequency (TF-IDF) feature representation. This approach effectively captures statistical, semantic, and syntactic aspects of text features through a weighted voting ensemble of machine learning models.	 | 剽窃是指未经授权使用他人的作品或概念，并将其呈现为原创创作。随着越来越多的数据以区域语言（如印度的马哈拉施特拉语）传播，设计适合低资源语言的 robust 原创性检测系统显得尤为重要。像双向编码器表示（BERT）这样的语言模型在文本表示和特征提取方面展现了非凡的能力，使其成为语义分析和原创性检测的重要工具。然而，BERT 在低资源语言中的应用仍然相对不足，特别是在原创性检测领域。本文提出了一种方法，通过结合 BERT 句向量表示和术语频率-逆文档频率（TF-IDF）特征表示，以提高马哈拉施特拉语文本原创性检测的准确性。该方法通过加权投票集成的机器学习模型，有效捕捉文本特征的统计、语义和句法方面。
2501.05234	 | Optimizing Estonian TV Subtitles with Semi-supervised Learning and LLMs	 | Artem Fedorchenko,Tanel Alumäe	 | 本文提出了一种通过微调 Whisper 模型并结合迭代伪标签和大型语言模型后编辑的方法，以生成高质量的爱沙尼亚语同语言字幕，并且实验表明这种方法能显著提升字幕质量，接近人类标准，并适合扩展到实时应用中。	 | This paper presents an approach for generating high-quality, same-language subtitles for Estonian TV content. We fine-tune the Whisper model on human-generated Estonian subtitles and enhance it with iterative pseudo-labeling and large language model (LLM) based post-editing. Our experiments demonstrate notable subtitle quality improvement through pseudo-labeling with an unlabeled dataset. We find that applying LLM-based editing at test time enhances subtitle accuracy, while its use during training does not yield further gains. This approach holds promise for creating subtitle quality close to human standard and could be extended to real-time applications.	 | 本文介绍了一种生成高质量同语言字幕的方法，适用于爱沙尼亚电视内容。我们通过对人工生成的爱沙尼亚语字幕进行微调 Whisper 模型，并结合迭代伪标签和基于大型语言模型（LLM）的后编辑，提升字幕质量。我们的实验表明，使用未标注数据集进行伪标签处理能显著提高字幕质量。我们发现，在测试时应用基于 LLM 的编辑可以增强字幕的准确性，而在训练过程中使用 LLM 编辑则不会带来进一步的提升。这种方法有望接近人类标准的字幕质量，并且可以扩展到实时应用中。
2501.05224	 | Leveraging Large Language Models for Zero-shot Lay Summarisation in Biomedicine and Beyond	 | Tomas Goldsack,Carolina Scarton,Chenghua Lin	 | 该研究探索了大型语言模型在零样本Lay总结中的应用，提出了一种新的两阶段框架，并发现生成的摘要随模型规模增大更受人类评审员青睐。研究还评估了LLM作为评审员的能力，并将其方法应用于NLP文章的Lay总结，进一步证明了其摘要的实用性和有效性。	 | In this work, we explore the application of Large Language Models to zero-shot Lay Summarisation. We propose a novel two-stage framework for Lay Summarisation based on real-life processes, and find that summaries generated with this method are increasingly preferred by human judges for larger models. To help establish best practices for employing LLMs in zero-shot settings, we also assess the ability of LLMs as judges, finding that they are able to replicate the preferences of human judges. Finally, we take the initial steps towards Lay Summarisation for Natural Language Processing (NLP) articles, finding that LLMs are able to generalise to this new domain, and further highlighting the greater utility of summaries generated by our proposed approach via an in-depth human evaluation.	 | 在本工作中，我们探究了大型语言模型在零样本 Lay 总结中的应用。我们提出了一个新的基于实际过程的两阶段框架用于 Lay 总结，并发现使用该方法生成的摘要随着模型规模的增大越来越受到人类评审员的偏好。为了帮助建立在零样本设置中使用 LLM 的最佳实践，我们还评估了 LLM 作为评审员的能力，发现它们能够复制人类评审员的偏好。最后，我们朝着将 Lay 总结应用于自然语言处理（NLP）文章的方向迈出第一步，发现 LLM 能够推广到这一新领域，并通过深度的人类评价进一步强调了我们提出的方法生成的摘要的更大实用性。
2501.05222	 | ParaRev: Building a dataset for Scientific Paragraph Revision annotated with revision instruction	 | Léane Jourdan,Nicolas Hernandez,Richard Dufour,Florian Boudin,Akiko Aizawa	 | 本文探讨了从句子级别转向段落级别进行科学文本修订的影响，并引入了首个包含手动标注修订指令的ParaRev数据集，实验结果表明，使用详细的修订指令能够显著提高自动修订的质量。	 | Revision is a crucial step in scientific writing, where authors refine their work to improve clarity, structure, and academic quality. Existing approaches to automated writing assistance often focus on sentence-level revisions, which fail to capture the broader context needed for effective modification. In this paper, we explore the impact of shifting from sentence-level to paragraph-level scope for the task of scientific text revision. The paragraph level definition of the task allows for more meaningful changes, and is guided by detailed revision instructions rather than general ones. To support this task, we introduce ParaRev, the first dataset of revised scientific paragraphs with an evaluation subset manually annotated with revision instructions. Our experiments demonstrate that using detailed instructions significantly improves the quality of automated revisions compared to general approaches, no matter the model or the metric considered.	 | 修订是科学写作中的一个关键步骤，作者通过这一过程完善其作品，提高其清晰度、结构和学术质量。现有的自动写作辅助方法通常侧重于句子级别的修订，这往往会忽视有效修改所需的更广泛背景。本文探讨了从句子级别转向段落级别对科学文本修订任务的影响。段落级别的任务定义能够实现更有意义的变化，并受到详细的修订指令而非一般指令的引导。为了支持这一任务，我们引入了ParaRev数据集，这是首个包含手动标注修订指令的修订科学段落数据集，并包含了一个评估子集。我们的实验表明，使用详细的指令能够显著提高自动修订的质量，无论采用哪种模型或评价指标。
2501.05213	 | GLaM-Sign: Greek Language Multimodal Lip Reading with Integrated Sign Language Accessibility	 | Dimitris Kouremenos,Klimis Ntalianis	 | GLaM-Sign是一个开创性的资源，旨在通过多模态唇读和手语翻译支持聋人和听力障碍者，主要服务于希腊旅游业，同时也适用于教育、医疗和公共服务领域，未来将提高精确度并支持多种语言扩展。	 | The Greek Language Multimodal Lip Reading with Integrated Sign Language Accessibility (GLaM-Sign) [1] is a groundbreaking resource in accessibility and multimodal AI, designed to support Deaf and Hard-of-Hearing (DHH) individuals. Developed from the FEELIT project [2], it integrates high-resolution audio, video, textual transcriptions, and Greek Sign Language translations for applications like real-time sign language translation and enhanced subtitle synchronization. While its primary focus is on promoting inclusivity in the Greek tourism sector, its adaptability extends to education, healthcare, and public services. Future advancements will enhance word-level precision and scalability to additional languages, supported by advanced AI methodologies and collaborations with diverse stakeholders. This dataset underscores the transformative potential of multimodal resources in bridging communication gaps, fostering innovation, and setting a benchmark for ethical AI and inclusive technologies.	 | 希腊语多模态唇读与集成手语无障碍访问(GLaM-Sign) [1] 是一个在无障碍和多模态AI领域具有开创性的资源，旨在支持聋人和听力障碍者（DHH）群体。该项目源自FEELIT项目[2]，整合了高分辨率音频、视频、文本转录以及希腊手语翻译，适用于实时手语翻译和增强了字幕同步的应用。虽然其主要关注点在于促进希腊旅游业的包容性，但其适应性扩展到了教育、医疗和公共服务领域。未来的发展将提高单词级别的精确度，并支持多种语言的扩展，这得益于先进的AI方法论和与多元利益相关方的合作。这个数据集强调了多模态资源在弥合沟通差距、促进创新以及为伦理AI和包容性技术设定标杆方面的发展潜力。
2501.05122	 | Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model	 | Gregor Geigle,Florian Schneider,Carolin Holtermann,Chris Biemann,Radu Timofte,Anne Lauscher,Goran Glavaš	 | 本研究全面探索了大规模多语言视觉-语言模型的训练策略，发现同时使用多达100种训练语言并确保25-50%的非英文数据可以显著提高多语言性能同时保持英文性能；基于此，研究团队训练了一个包含100种语言的模型Centurio，该模型在多种任务和语言上的评估中表现出色。	 | Most Large Vision-Language Models (LVLMs) to date are trained predominantly on English data, which makes them struggle to understand non-English input and fail to generate output in the desired target language. Existing efforts mitigate these issues by adding multilingual training data, but do so in a largely ad-hoc manner, lacking insight into how different training mixes tip the scale for different groups of languages. In this work, we present a comprehensive investigation into the training strategies for massively multilingual LVLMs. First, we conduct a series of multi-stage experiments spanning 13 downstream vision-language tasks and 43 languages, systematically examining: (1) the number of training languages that can be included without degrading English performance and (2) optimal language distributions of pre-training as well as (3) instruction-tuning data. Further, we (4) investigate how to improve multilingual text-in-image understanding, and introduce a new benchmark for the task. Surprisingly, our analysis reveals that one can (i) include as many as 100 training languages simultaneously (ii) with as little as 25-50\% of non-English data, to greatly improve multilingual performance while retaining strong English performance. We further find that (iii) including non-English OCR data in pre-training and instruction-tuning is paramount for improving multilingual text-in-image understanding. Finally, we put all our findings together and train Centurio, a 100-language LVLM, offering state-of-the-art performance in an evaluation covering 14 tasks and 56 languages.	 | 截至目前，大多数大型视觉-语言模型（LVLMs）主要是用英文数据训练的，这使得它们在理解非英文输入和生成目标语言输出方面表现出色。现有的努力通过添加多语言训练数据来缓解这些问题，但这大多是一种临时的方法，缺乏对不同训练语言混合如何影响不同语言组的洞察。在本工作中，我们对大规模多语言LVLM的训练策略进行了全面研究。首先，我们进行了一系列多阶段实验，涵盖13个下游视觉-语言任务和43种语言，系统地探讨了以下问题：（1）可以包含多少种训练语言而不损害英文性能；（2）预训练和（3）指令调整数据的最佳语言分布。此外，我们（4）研究如何提高多语言文本-图像理解，并引入了一个新的基准测试任务。令人惊讶的是，我们的分析揭示，可以通过以下方式显著提高多语言性能并保留强大的英文性能：（i）同时包含多达100种训练语言（ii）使用25-50%的非英文数据。我们还发现，（iii）在预训练和指令调整数据中包含非英文OCR数据对于提高多语言文本-图像理解至关重要。最后，我们将所有这些发现结合起来，训练了一个包含100种语言的LVLM——Centurio，它在涵盖14个任务和56种语言的评估中表现出领先性能。
2501.05040	 | SWE-Fixer: Training Open-Source LLMs for Effective and Efficient GitHub Issue Resolution	 | Chengxing Xie,Bowen Li,Chang Gao,He Du,Wai Lam,Difan Zou,Kai Chen	 | SWE-Fixer是一个开源大型语言模型系统，旨在有效解决GitHub上的编程问题，它通过结合BM25和轻量级LLM进行代码文件检索，并使用另一个LLM生成补丁，从而在评估基准上取得了开源模型中的最佳性能。	 | Large Language Models (LLMs) have demonstrated remarkable proficiency across a variety of complex tasks. One significant application of LLMs is in tackling software engineering challenges, particularly in resolving real-world tasks on GitHub by fixing code based on the issues reported by the users. However, many current approaches rely on proprietary LLMs, which limits reproducibility, accessibility, and transparency. The critical components of LLMs for addressing software engineering issues and how their capabilities can be effectively enhanced remain unclear. To address these challenges, we introduce SWE-Fixer, a novel open-source LLM designed to effectively and efficiently resolve GitHub issues. SWE-Fixer comprises two essential modules: a code file retrieval module and a code editing module. The retrieval module employs BM25 along with a lightweight LLM model to achieve coarse-to-fine file retrieval. Subsequently, the code editing module utilizes the other LLM model to generate patches for the identified files. Then, to mitigate the lack of publicly available datasets, we compile an extensive dataset that includes 110K GitHub issues along with their corresponding patches, and train the two modules of SWE-Fixer separately. We assess our approach on the SWE-Bench Lite and Verified benchmarks, achieving state-of-the-art performance among open-source models with scores of 23.3% and 30.2%, respectively. These outcomes highlight the efficacy of our approach. We will make our model, dataset, and code publicly available at https://github.com/InternLM/SWE-Fixer.	 | 大型语言模型（LLMs）在各种复杂任务中展现出了显著的能力。LLMs的一个重要应用是解决软件工程挑战，特别是在GitHub上通过修复代码来解决用户报告的问题。然而，目前许多方法依赖于专有的LLMs，这限制了其可重现性、可访问性和透明度。用于解决软件工程问题的LLMs的关键组件及其能力如何有效提升仍不清楚。为了解决这些问题，我们介绍了SWE-Fixer，这是一个新颖的开源LLM，旨在有效且高效地解决GitHub问题。SWE-Fixer包含两个关键模块：代码文件检索模块和代码编辑模块。检索模块利用BM25与轻量级LLM模型相结合，实现粗到细的文件检索。随后，代码编辑模块使用另一个LLM模型生成已识别文件的补丁。此外，为了解决可用数据集缺乏的问题，我们编译了一个包含110K GitHub问题及其对应补丁的广泛数据集，并分别训练SWE-Fixer的两个模块。我们在SWE-Bench Lite和Verified基准上评估了我们的方法，分别取得了开源模型中的最佳性能，得分为23.3%和30.2%。这些结果突显了我们方法的有效性。我们将我们的模型、数据集和代码公开在https://github.com/InternLM/SWE-Fixer。
2501.05032	 | Enhancing Human-Like Responses in Large Language Models	 | Ethem Yağız Çalık,Talha Rüzgar Akkuş	 | 本文探讨了通过使用多样化数据集、融合心理学原理和设计更接近人类推理模式的方法，提升大型语言模型的自然语言理解能力、对话连贯性和情感智能，以使AI更加人性化，并为跨领域应用开辟新可能性。未来研究将关注这些改进所带来的伦理问题和潜在偏见。	 | This paper explores the advancements in making large language models (LLMs) more human-like. We focus on techniques that enhance natural language understanding, conversational coherence, and emotional intelligence in AI systems. The study evaluates various approaches, including fine-tuning with diverse datasets, incorporating psychological principles, and designing models that better mimic human reasoning patterns. Our findings demonstrate that these enhancements not only improve user interactions but also open new possibilities for AI applications across different domains. Future work will address the ethical implications and potential biases introduced by these human-like attributes.	 | 本文探讨了使大型语言模型（LLMs）更加人性化的发展。我们重点关注提高人工智能系统自然语言理解能力、对话连贯性和情感智能的各种技术。研究评估了包括使用多样化数据集进行微调、融入心理学原理以及设计更接近人类推理模式的模型在内的各种方法。我们的研究结果表明，这些改进不仅提高了用户交互的质量，还为跨不同领域的AI应用开辟了新的可能性。未来的研究将关注这些人性化特征所带来的伦理问题和潜在偏见。
2501.04987	 | TreeKV: Smooth Key-Value Cache Compression with Tree Structures	 | Ziwei He,Jian Yuan,Haoli Bai,Jingwen Leng,Bo Jiang	 | TreeKV 是一种无需训练的 KV 缓存压缩方法，利用树结构在保持固定缓存大小的同时有效压缩基于变压器的大型语言模型的键值缓存，显著提高了模型在长文本上的性能，并在多个语言建模任务中优于现有基线。	 | Efficient key-value (KV) cache compression is critical for scaling transformer-based Large Language Models (LLMs) in long sequences and resource-limited settings. Existing methods evict tokens based on their positions or importance scores, but position-based strategies can miss crucial information outside predefined regions, while those relying on global importance scores resulting in strong regional biases, limiting the KV cache's overall context retention and potentially impairing the performance of LLMs on complex tasks. Our wavelet analysis reveals that as tokens approach the end of sequence, their contributions to generation gradually increase and tends to diverge more from neighboring tokens, indicating a smooth transition with increasing complexity and variability from distant to nearby context. Motivated by this observation, we propose TreeKV, an intuitive, training-free method that employs a tree structure for smooth cache compression. TreeKV maintains a fixed cache size, allowing LLMs to deliver high-quality output even in long text scenarios. Unlike most compression methods, TreeKV is applicable to both the generation and prefilling stages. It consistently surpasses all baseline models in language modeling tasks on PG19 and OpenWebText2, allowing LLMs trained with short context window to generalize to longer window with a 16x cache reduction. On the Longbench benchmark, TreeKV achieves the best performance with only 6\% of the budget at optimal efficiency.	 | 对于基于变压器的大型语言模型（LLMs）在长序列和资源受限环境下的扩展，高效的键值（KV）缓存压缩至关重要。现有方法基于位置或重要性分数移除令牌，但基于位置的策略可能会忽略预定义区域之外的重要信息，而依赖全局重要性分数的方法则会导致强烈的区域偏见，限制了KV缓存的整体上下文保留能力，并可能影响LLMs在复杂任务上的性能。我们的小波分析显示，随着令牌接近序列末尾，它们对生成的贡献逐渐增加，并且往往会与相邻令牌产生更大的差异，表明从远处到近处的上下文具有平滑过渡，并且复杂性和可变性逐渐增强。受这一观察的启发，我们提出了TreeKV，这是一种直观且无需训练的方法，使用树结构进行平滑缓存压缩。TreeKV 保持固定的缓存大小，即使在长文本场景下，LLMs 也能提供高质量的输出。与大多数压缩方法不同，TreeKV 在生成和预填充阶段都是适用的。在 PG19 和 OpenWebText2 的语言建模任务中，TreeKV 一直超过所有基线模型，并允许使用短上下文窗口训练的 LLMs 在长上下文窗口下泛化，同时仅减少 16 倍的缓存。在 Longbench 指标中，TreeKV 仅以 6% 的预算实现了最佳性能，并且效率最优。
2501.04974	 | SensorQA: A Question Answering Benchmark for Daily-Life Monitoring	 | Benjamin Reichman,Xiaofan Yu,Lanxiang Hu,Jack Truxal,Atishay Jain,Rushil Chandrupatla,Tajana Šimunić Rosing,Larry Heck	 | 本文介绍了首个用于日常生命监测的长期时间序列传感器数据人工创建问答数据集SensorQA，包含5600多个反映真实用户兴趣的查询和答案，并展示了现有AI模型与最优问答性能之间的差距，突显了新的研究贡献的必要性。	 | With the rapid growth in sensor data, effectively interpreting and interfacing with these data in a human-understandable way has become crucial. While existing research primarily focuses on learning classification models, fewer studies have explored how end users can actively extract useful insights from sensor data, often hindered by the lack of a proper dataset. To address this gap, we introduce \Dataset, the first human-created question-answering (QA) dataset for long-term time-series sensor data for daily life monitoring. \Dataset is created by human workers and includes 5.6K diverse and practical queries that reflect genuine human interests, paired with accurate answers derived from sensor data. We further establish benchmarks for state-of-the-art AI models on this dataset and evaluate their performance on typical edge devices. Our results reveal a gap between current models and optimal QA performance and efficiency, highlighting the need for new contributions. The dataset and code are available at: \url{https://github.com/benjamin-reichman/SensorQA}.	 | 随着传感器数据的迅速增长，有效地在人类可理解的方式下解读和处理这些数据变得至关重要。现有研究主要集中在学习分类模型上，而较少探讨最终用户如何积极地从传感器数据中提取有用的信息，这往往受到缺乏适当数据集的阻碍。为了解决这一问题，我们引入了\Dataset，这是首个为日常生命监测设计的长期时间序列传感器数据的人工创建问答（QA）数据集。\Dataset 是由人工工人创建的，并包含5600多个多样化且实用的查询，反映了真实的用户兴趣，这些问题答案都基于传感器数据准确生成。我们还为最先进的AI模型在这数据集上建立了基准，并在典型边缘设备上评估了它们的表现。我们的结果显示现有模型与最优的问答性能和效率之间存在差距，突显了新贡献的必要性。数据集和代码可在以下链接获取：\url{https://github.com/benjamin-reichman/SensorQA}。
2501.04962	 | VoxEval: Benchmarking the Knowledge Understanding Capabilities of End-to-End Spoken Language Models	 | Wenqian Cui,Xiaoqi Jiao,Ziqiao Meng,Irwin King	 | VoxEval是一种新的语音问答基准，旨在评估基于语音的语言模型在各种音频条件下的知识理解能力，特别适用于评估模型在处理数学问题求解等复杂领域的表现。研究表明，当前的模型在VoxEval上的性能存在显著限制，揭示了未来研究的关键方向。	 | With the growing demand for developing speech-based interaction models, end-to-end Spoken Language Models (SLMs) have emerged as a promising solution. When engaging in conversations with humans, it is essential for these models to comprehend a wide range of world knowledge. In this paper, we introduce VoxEval, a novel speech question-answering benchmark specifically designed to assess SLMs' knowledge understanding through purely speech-based interactions. Unlike existing AudioQA benchmarks, VoxEval maintains speech format for both questions and answers, evaluates model robustness across diverse audio conditions (varying timbres, audio qualities, and speaking styles), and pioneers the assessment of challenging domains like mathematical problem-solving in spoken format. Our comprehensive evaluation of recent SLMs using VoxEval reveals significant performance limitations in current models, highlighting crucial areas for future improvements.	 | 随着对基于语音的交互模型需求的增长，端到端的语音语言模型（SLMs）已成为一种有前途的解决方案。当这些模型与人类进行对话时，理解广泛的世界知识是至关重要的。在本文中，我们介绍了VoxEval，这是一种新的语音问答基准，专门设计用于通过纯语音交互评估SLMs的知识理解能力。与现有的音频问答（AudioQA）基准不同，VoxEval保持了语音格式，用于问题和答案的评估，并且评估模型在各种音频条件（包括不同音色、音频质量和说话风格）下的鲁棒性。此外，VoxEval还率先通过语音形式评估了诸如数学问题求解等具有挑战性的领域。我们对最近的SLMs使用VoxEval进行的全面评估揭示了当前模型中存在显著的性能限制，突显了未来改进的关键领域。
2501.04961	 | Demystifying Domain-adaptive Post-training for Financial LLMs	 | Zixuan Ke,Yifei Ming,Xuan-Phi Nguyen,Caiming Xiong,Shafiq Joty	 | 该研究提出了FINDAP（Finance Domain Adaptation Post-Training）方法，旨在优化大规模语言模型在金融领域的适应性后训练，通过全面评估体系和新颖的偏好数据精炼方法，最终在多项金融任务中取得了最先进的性能。	 | Domain-adaptive post-training of large language models (LLMs) has emerged as a promising approach for specialized domains such as medicine and finance. However, significant challenges remain in identifying optimal adaptation criteria and training strategies across varying data and model configurations. To address these challenges, we introduce FINDAP, a systematic and fine-grained investigation into domain-adaptive post-training of LLMs for the finance domain. Our approach begins by identifying the core capabilities required for the target domain and designing a comprehensive evaluation suite aligned with these needs. We then analyze the effectiveness of key post-training stages, including continual pretraining, instruction tuning, and preference alignment. Building on these insights, we propose an effective training recipe centered on a novel preference data distillation method, which leverages process signals from a generative reward model. The resulting model, Llama-Fin, achieves state-of-the-art performance across a wide range of financial tasks. Our analysis also highlights how each post-training stage contributes to distinct capabilities, uncovering specific challenges and effective solutions, providing valuable insights for domain adaptation of LLMs. Project page: https://github.com/SalesforceAIResearch/FinDap	 | 大规模语言模型（LLMs）在特定领域如医学和金融中的适应性后训练逐渐成为一种有前景的方法。然而，不同数据和模型配置下最优适应标准和训练策略的选择仍然面临着重大挑战。为应对这些挑战，我们引入了 FINDAP（Finance Domain Adaptation Post-Training），一种系统且精细的方法，用于金融领域的LLMs适应性后训练。我们的方法始于识别目标领域所需的核心能力，并设计一个与这些需求相一致的全面评估体系。随后，我们分析了关键后训练阶段的有效性，包括持续预训练、指令调优和偏好对齐。基于这些洞见，我们提出了一种以新颖的偏好数据精炼方法为中心的有效训练方案，该方法利用生成奖励模型中的过程信号。最终模型 Llama-Fin 在多种金融任务中均达到了最先进的性能。我们的分析还揭示了每个后训练阶段所贡献的独特能力，发现了特定的挑战和有效的解决方案，为LLMs的领域适应提供了宝贵的见解。项目页面：https://github.com/SalesforceAIResearch/FinDap
2501.04945	 | Step-by-Step Mastery: Enhancing Soft Constraint Following Ability of Large Language Models	 | Qingyu Ren,Jie Zeng,Qianyu He,Jiaqing Liang,Yanghua Xiao,Weikang Zhou,Zeye Sun,Fei Yu	 | 该研究设计了一种流水线自动获取高质量输出，并提出了一种基于渐进学习的训练方法，以增强大型语言模型遵循涉及语义相关软约束的能力，并公开了相关数据集和代码。	 | It is crucial for large language models (LLMs) to follow instructions that involve multiple constraints. However, soft constraints are semantically related and difficult to verify through automated methods. These constraints remain a significant challenge for LLMs. To enhance the ability of LLMs to follow soft constraints, we initially design a pipeline to obtain high-quality outputs automatically. Additionally, to fully utilize the acquired data, we introduce a training paradigm based on curriculum learning. We experimentally evaluate the effectiveness of our methods in improving LLMs' soft constraint following ability and analyze the factors driving the improvements. The datasets and code are publicly available at https://github.com/Rainier-rq/FollowSoftConstraints.	 | 对于大型语言模型（LLMs）而言，遵循涉及多个约束的指令至关重要。然而，软约束是语义相关的，难以通过自动化方法进行验证，这些约束仍然是LLMs的一个重大挑战。为了增强LLMs遵循软约束的能力，我们首先设计了一个流水线，以自动获取高质量的输出。此外，为了充分利用获取的数据，我们引入了一种基于渐进学习的训练范式。我们通过实验评估了我们方法在提高LLMs遵循软约束能力方面的有效性，并分析了推动改进的因素。相关数据集和代码可在 https://github.com/Rainier-rq/FollowSoftConstraints 公开获得。
2501.04927	 | Investigating Numerical Translation with Large Language Models	 | Wei Tang,Jiawei Yu,Yuang Li,Yanqing Zhao,Weidong Zhang,Wei Feng,Min Zhang,Hao Yang	 | 研究评估了基于大型语言模型（LLMs）的机器翻译系统在处理数值数据时的可靠性，发现大多数开源LLM在翻译涉及“百万”、“亿”等大单位的数字时错误率高达20%；研究还提出三种策略以减轻大单位数字误译的问题。	 | The inaccurate translation of numbers can lead to significant security issues, ranging from financial setbacks to medical inaccuracies. While large language models (LLMs) have made significant advancements in machine translation, their capacity for translating numbers has not been thoroughly explored. This study focuses on evaluating the reliability of LLM-based machine translation systems when handling numerical data. In order to systematically test the numerical translation capabilities of currently open source LLMs, we have constructed a numerical translation dataset between Chinese and English based on real business data, encompassing ten types of numerical translation. Experiments on the dataset indicate that errors in numerical translation are a common issue, with most open-source LLMs faltering when faced with our test scenarios. Especially when it comes to numerical types involving large units like ``million", ``billion", and "yi", even the latest llama3.1 8b model can have error rates as high as 20%. Finally, we introduce three potential strategies to mitigate the numerical mistranslations for large units.	 | 不准确地翻译数字可能会导致重大安全问题，从财务损失到医疗错误不一而足。尽管大型语言模型（LLMs）在机器翻译方面取得了显著进步，但它们在处理数字方面的能力尚未得到充分研究。本研究的重点是评估基于LLM的机器翻译系统在处理数值数据时的可靠性。为了系统地测试当前开源LLM的数字翻译能力，我们基于实际业务数据构建了一个中英文数字翻译数据集，涵盖了十种类型的数字翻译。实验结果表明，数字翻译中的错误是一个常见问题，大多数开源LLM在面对我们测试场景时都会出现问题。特别是对于涉及“百万”、“亿”等大单位的数字类型，即使是最新的llama3.1 8b模型，错误率也可能高达20%。最后，我们介绍了三种潜在的策略，以减轻大单位数字误译的问题。
2501.04904	 | JELLY: Joint Emotion Recognition and Context Reasoning with LLMs for Conversational Speech Synthesis	 | Jun-Hyeok Cha,Seung-Bin Kim,Hyung-Seok Oh,Seong-Whan Lee	 | JELLY 是一种结合情绪识别和上下文推理的新颖对话语音合成框架，通过微调大型语言模型和 LoRA 模块生成符合对话情绪的语音；实验结果表明 JELLY 在情绪上下文建模方面表现出色，能够生成自然契合对话的语音。	 | Recently, there has been a growing demand for conversational speech synthesis (CSS) that generates more natural speech by considering the conversational context. To address this, we introduce JELLY, a novel CSS framework that integrates emotion recognition and context reasoning for generating appropriate speech in conversation by fine-tuning a large language model (LLM) with multiple partial LoRA modules. We propose an Emotion-aware Q-former encoder, which enables the LLM to perceive emotions in speech. The encoder is trained to align speech emotions with text, utilizing datasets of emotional speech. The entire model is then fine-tuned with conversational speech data to infer emotional context for generating emotionally appropriate speech in conversation. Our experimental results demonstrate that JELLY excels in emotional context modeling, synthesizing speech that naturally aligns with conversation, while mitigating the scarcity of emotional conversational speech datasets.	 | 最近，对基于对话的语音合成（CSS）的需求正在增长，这种技术通过考虑对话上下文生成更加自然的语音。为应对这一需求，我们引入了JELLY，这是一种新颖的CSS框架，结合了情绪识别和上下文推理，通过微调大型语言模型（LLM）和多个部分LoRA模块来生成合适的对话语音。我们提出了一种情绪感知的Q-former编码器，使LLM能够感知语音中的情绪。该编码器被训练以将语音情绪与文本对齐，利用情绪语音的数据集。整个模型随后通过对话语音数据进行微调，以推断情绪上下文，从而生成符合对话情绪的语音。我们的实验结果表明，JELLY 在情绪上下文建模方面表现出色，能够生成自然契合对话的语音，同时减轻了情绪对话语音数据集稀缺的问题。
2501.04899	 | SUGAR: Leveraging Contextual Confidence for Smarter Retrieval	 | Hanna Zubkova,Ji-Hoon Park,Seong-Whan Lee	 | 为了提高大型语言模型的响应质量和效率，提出了语义不确定性引导的自适应检索（SUGAR）方法，该方法利用上下文熵来决定是否进行检索，并进一步确定检索的深度，从而减少无用检索和提高来源效率。	 | Bearing in mind the limited parametric knowledge of Large Language Models (LLMs), retrieval-augmented generation (RAG) which supplies them with the relevant external knowledge has served as an approach to mitigate the issue of hallucinations to a certain extent. However, uniformly retrieving supporting context makes response generation source-inefficient, as triggering the retriever is not always necessary, or even inaccurate, when a model gets distracted by noisy retrieved content and produces an unhelpful answer. Motivated by these issues, we introduce Semantic Uncertainty Guided Adaptive Retrieval (SUGAR), where we leverage context-based entropy to actively decide whether to retrieve and to further determine between single-step and multi-step retrieval. Our empirical results show that selective retrieval guided by semantic uncertainty estimation improves the performance across diverse question answering tasks, as well as achieves a more efficient inference.	 | 考虑到大型语言模型（LLMs）参数知识的有限性，检索增强生成（RAG）通过提供相关外部知识来缓解幻觉问题，已经在一定程度上起到了作用。然而，均匀地检索支持性上下文使得响应生成在来源效率上有所损失，因为当模型被嘈杂的检索内容吸引并生成无用的答案时，触发检索器并不总是必要的，甚至可能是不准确的。基于这些问题，我们提出了语义不确定性引导的自适应检索（SUGAR），其中我们利用上下文熵来主动决定是否进行检索，并进一步确定是进行单步检索还是多步检索。我们的实验结果表明，基于语义不确定性估计的有选择性的检索可以提高各种问答任务的性能，同时还实现了更高效的推理。
2501.04880	 | Leveraging Log Probabilities in Language Models to Forecast Future Events	 | Tommaso Soru,Jim Marshall	 | 本文介绍了一种使用大型语言模型（LLMs）进行AI驱动展望的新方法，通过基于对数概率的多步方法估计预测的概率，结果显示该方法在多个主题上的布里尔得分显著优于随机猜测和现有AI系统。	 | In the constantly changing field of data-driven decision making, accurately predicting future events is crucial for strategic planning in various sectors. The emergence of Large Language Models (LLMs) marks a significant advancement in this area, offering advanced tools that utilise extensive text data for prediction. In this industry paper, we introduce a novel method for AI-driven foresight using LLMs. Building on top of previous research, we employ data on current trends and their trajectories for generating forecasts on 15 different topics. Subsequently, we estimate their probabilities via a multi-step approach based on log probabilities. We show we achieve a Brier score of 0.186, meaning a +26% improvement over random chance and a +19% improvement over widely-available AI systems.	 | 在不断变化的数据驱动决策领域中，准确预测未来事件对于各行业的战略规划至关重要。大型语言模型（LLMs）的出现标志着这一领域的重大进展，它们利用大量文本数据提供了先进的预测工具。在本文中，我们介绍了一种使用LLMs进行AI驱动展望的新方法。我们建立在先前研究的基础上，利用当前趋势及其轨迹的数据，为15个不同主题生成预测。随后，我们通过基于对数概率的多步方法估计这些预测的概率。结果显示，我们实现了0.186的布里尔得分，这意味着比随机猜测高出26%，比广泛使用的AI系统高出19%。
2501.04877	 | Real-Time Textless Dialogue Generation	 | Long Mai,Julie Carson-Berndsen	 | 近年来，虽然大型语言模型推动了基于文本的对话系统取得显著进步，但实时口语对话系统仍存在响应自然性不足的问题。为解决这一挑战，本文提出了一种新的实时、无需文本的口语对话生成模型（RTTL-DG），该模型能够实现流畅的对话轮换，并通过直接处理流式口语对话来生成更加自然和人性化的互动。	 | Recent advancements in large language models (LLMs) have led to significant progress in text-based dialogue systems. These systems can now generate high-quality responses that are accurate and coherent across a wide range of topics and tasks. However, spoken dialogue systems still lag behind in terms of naturalness. They tend to produce robotic interactions, with issues such as slow response times, overly generic or cautious replies, and a lack of natural rhythm and fluid turn-taking. This shortcoming is largely due to the over-reliance on the traditional cascaded design, which involve separate, sequential components, as well as the use of text as an intermediate representation. This paper propose a real-time, textless spoken dialogue generation model (RTTL-DG) that aims to overcome these challenges. Our system enables fluid turn-taking and generates responses with minimal delay by processing streaming spoken conversation directly. Additionally, our model incorporates backchannels, filters, laughter, and other paralinguistic signals, which are often absent in cascaded dialogue systems, to create more natural and human-like interactions. The implementations and generated samples are available in our repository: https://github.com/mailong25/rts2s-dg	 | 近年来，大型语言模型（LLMs）的最新进展推动了基于文本的对话系统取得了显著进步。这些系统现在可以生成高质量、准确且连贯的响应，覆盖广泛的话题和任务。然而，口语对话系统在自然性方面仍落后于文本对话系统。它们往往会产生机械化的互动，存在响应迟缓、回答过于通用或谨慎、缺乏自然节奏和流畅对话轮换等问题。这些不足主要是由于对传统分阶段设计的过度依赖，这种设计包含一系列顺序执行的组件，以及使用文本作为中间表示形式所致。本文提出了一种实时、无需文本的口语对话生成模型（RTTL-DG），旨在克服这些挑战。我们的系统能够实现流畅的对话轮换，并通过直接处理流式口语对话来生成响应，从而减少延迟。此外，我们的模型还整合了回音、过滤器、笑声和其他副语言信号，这些信号在分阶段对话系统中通常缺失，从而创建出更为自然和人性化互动。模型的实现和生成样本可在我们的代码库中获得：https://github.com/mailong25/rts2s-dg
2501.04858	 | Advancing Retrieval-Augmented Generation for Persian: Development of Language Models, Comprehensive Benchmarks, and Best Practices for Optimization	 | Sara Bourbour Hosseinbeigi,Sina Asghari,Mohammad Ali Seif Kashani,Mohammad Hossein Shalchian,Mohammad Amin Abbasi	 | 本文探讨了在波斯语中构建检索增强生成（RAG）系统的挑战，并通过引入专门的波斯语模型MatinaRoberta和MatinaSRoberta以及一个全面的基准测试框架，提高了检索和生成的准确性，特别是在通用知识、科学专著文本和组织报告数据集上的表现。	 | This paper examines the specific obstacles of constructing Retrieval-Augmented Generation(RAG) systems in low-resource languages, with a focus on Persian's complicated morphology and versatile syntax. The research aims to improve retrieval and generation accuracy by introducing Persian-specific models, namely MatinaRoberta(a masked language model) and MatinaSRoberta(a fine-tuned Sentence-BERT), along with a comprehensive benchmarking framework. Three datasets-general knowledge(PQuad), scientifically specialized texts, and organizational reports, were used to assess these models after they were trained on a varied corpus of 73.11 billion Persian tokens. The methodology involved extensive pretraining, fine-tuning with tailored loss functions, and systematic evaluations using both traditional metrics and the Retrieval-Augmented Generation Assessment framework. The results show that MatinaSRoberta outperformed previous embeddings, achieving superior contextual relevance and retrieval accuracy across datasets. Temperature tweaking, chunk size modifications, and document summary indexing were explored to enhance RAG setups. Larger models like Llama-3.1 (70B) consistently demonstrated the highest generation accuracy, while smaller models faced challenges with domain-specific and formal contexts. The findings underscore the potential for developing RAG systems in Persian through customized embeddings and retrieval-generation settings and highlight the enhancement of NLP applications such as search engines and legal document analysis in low-resource languages.	 | 本文探讨了在低资源语言中构建检索增强生成（RAG）系统的特定障碍，重点关注波斯语复杂的形态和多样的句法。研究旨在通过引入波斯语特定模型——MatinaRoberta（一种掩码语言模型）和MatinaSRoberta（微调的Sentence-BERT）以及一个全面的基准测试框架，来提高检索和生成的准确性。使用了三个数据集：通用知识（PQuad）、科学专著文本和组织报告，对这些模型进行了评估，这些模型是在包含731.1亿个波斯语词的多样化语料库上进行训练的。研究方法包括广泛的预训练、使用定制损失函数的微调以及使用传统指标和检索增强生成评估框架进行系统的评估。结果表明，MatinaSRoberta在各个数据集上表现出更高的上下文相关性和检索准确性，超越了之前的嵌入模型。温度调整、段落大小的修改以及文本文档摘要索引被探索以改进RAG设置。较大的模型如Llama-3.1（70B）在生成准确性方面始终表现出最高水平，而较小的模型在特定领域和正式语境中面临挑战。研究结果强调了通过定制嵌入和检索生成设置开发波斯语RAG系统的能力，并突显了在低资源语言中提高自然语言处理（NLP）应用，如搜索引擎和法律文件分析的潜力。
2501.04828	 | Building Foundations for Natural Language Processing of Historical Turkish: Resources and Models	 | Şaziye Betül Özateş,Tarık Emre Tıraş,Ece Elif Adak,Berat Doğan,Fatih Burak Karagöz,Efe Eren Genç,Esma F. Bilgin Taşdemir	 | 本文介绍了历史土耳其语自然语言处理的基础资源和模型，包括首次提出的HisTR命名实体识别数据集和OTA-BOUN通用依存树库，以及清洁的历史土耳其语文本语料库奥斯曼文本语料库（OTC），并展示了在历史土耳其语计算分析方面取得的进展和面临的挑战。	 | This paper introduces foundational resources and models for natural language processing (NLP) of historical Turkish, a domain that has remained underexplored in computational linguistics. We present the first named entity recognition (NER) dataset, HisTR and the first Universal Dependencies treebank, OTA-BOUN for a historical form of the Turkish language along with transformer-based models trained using these datasets for named entity recognition, dependency parsing, and part-of-speech tagging tasks. Additionally, we introduce Ottoman Text Corpus (OTC), a clean corpus of transliterated historical Turkish texts that spans a wide range of historical periods. Our experimental results show significant improvements in the computational analysis of historical Turkish, achieving promising results in tasks that require understanding of historical linguistic structures. They also highlight existing challenges, such as domain adaptation and language variations across time periods. All of the presented resources and models are made available at https://huggingface.co/bucolin to serve as a benchmark for future progress in historical Turkish NLP.	 | 本文介绍了处理历史土耳其语自然语言处理（NLP）的基础资源和模型，这是一个在计算语言学中始终未得到充分探索的领域。我们首次提出了历史土耳其语命名实体识别（NER）数据集HisTR，并首次构建了历史土耳其语的通用依存树库OTA-BOUN。此外，我们还介绍了一部名为奥斯曼文本语料库（OTC）的清洁历史土耳其语文本语料库，涵盖了广泛的不同时期。我们的实验结果表明，在历史土耳其语的计算分析方面取得了显著的进步，特别是在需要理解历史语言结构的任务中取得了令人鼓舞的结果。同时，这些结果也突显了现有挑战，如领域适应和不同时期的语言变化。所有展示的资源和模型均可在https://huggingface.co/bucolin 获取，以作为未来历史土耳其语NLP进展的基准。
2501.04799	 | Cued Speech Generation Leveraging a Pre-trained Audiovisual Text-to-Speech Model	 | Sanjana Sankar,Martin Lenglet,Gerard Bailly,Denis Beautemps,Thomas Hueber	 | 本文提出了一种通过迁移学习策略利用预训练的AVTacotron2模型自动生成唇语的方法，并在两个数据集上实现了约77%的音位级解码准确率，证明了其有效性。	 | This paper presents a novel approach for the automatic generation of Cued Speech (ACSG), a visual communication system used by people with hearing impairment to better elicit the spoken language. We explore transfer learning strategies by leveraging a pre-trained audiovisual autoregressive text-to-speech model (AVTacotron2). This model is reprogrammed to infer Cued Speech (CS) hand and lip movements from text input. Experiments are conducted on two publicly available datasets, including one recorded specifically for this study. Performance is assessed using an automatic CS recognition system. With a decoding accuracy at the phonetic level reaching approximately 77%, the results demonstrate the effectiveness of our approach.	 | 本文提出了一种新颖的方法，用于自动生成唇语（Cued Speech，简称CS），这是一种用于听力障碍人士更好地传达口语的语言视觉通信系统。我们通过利用预训练的音频视觉自回归文本转语音模型（AVTacotron2）探索了迁移学习策略。该模型被重新编程，以从文本输入中推断出CS的手势和唇部动作。我们在两个公开可用的数据集上进行了实验，其中包括一个专门为本次研究录制的数据集。性能是通过一个自动的CS识别系统进行评估的。在音位级的解码准确率达到约77%的情况下，结果表明了我们方法的有效性。
2501.05452	 | ReFocus: Visual Editing as a Chain of Thought for Structured Image Understanding	 | Xingyu Fu,Minqian Liu,Zhengyuan Yang,John Corring,Yijuan Lu,Jianwei Yang,Dan Roth,Dinei Florencio,Cha Zhang	 | ReFocus 是一个简单有效的框架，通过允许多模态大型语言模型对输入图像进行视觉编辑和逐步修改，增强了模型的视觉推理能力，从而显著提升了表格和图表理解任务的表现。该框架不仅在多个任务上改进了现有模型，还通过收集包含视觉链式思考的训练集，提供了更好的监督，进一步提高了模型的效果。	 | Structured image understanding, such as interpreting tables and charts, requires strategically refocusing across various structures and texts within an image, forming a reasoning sequence to arrive at the final answer. However, current multimodal large language models (LLMs) lack this multihop selective attention capability. In this work, we introduce ReFocus, a simple yet effective framework that equips multimodal LLMs with the ability to generate "visual thoughts" by performing visual editing on the input image through code, shifting and refining their visual focuses. Specifically, ReFocus enables multimodal LLMs to generate Python codes to call tools and modify the input image, sequentially drawing boxes, highlighting sections, and masking out areas, thereby enhancing the visual reasoning process. We experiment upon a wide range of structured image understanding tasks involving tables and charts. ReFocus largely improves performance on all tasks over GPT-4o without visual editing, yielding an average gain of 11.0% on table tasks and 6.8% on chart tasks. We present an in-depth analysis of the effects of different visual edits, and reasons why ReFocus can improve the performance without introducing additional information. Further, we collect a 14k training set using ReFocus, and prove that such visual chain-of-thought with intermediate information offers a better supervision than standard VQA data, reaching a 8.0% average gain over the same model trained with QA pairs and 2.6% over CoT.	 | 结构化图像理解，例如解析表格和图表，需要在图像内的多种结构和文本之间有策略地重新聚焦，并形成推理序列以得出最终答案。然而，当前的多模态大型语言模型（LLMs）缺乏这种多跳选择性注意力的能力。在本文中，我们引入了ReFocus，这是一个简单而有效的框架，能够通过代码对输入图像进行视觉编辑，使多模态LLMs具备生成“视觉思考”的能力，即通过改变和细化视觉关注点。具体来说，ReFocus允许多模态LLMs生成Python代码来调用工具并修改输入图像，逐次绘制框、突出显示部分和遮盖区域，从而增强视觉推理过程。  我们对涉及表格和图表的多种结构化图像理解任务进行了实验。ReFocus在没有进行视觉编辑的GPT-4o上显著提高了所有任务的表现，在表格任务上的平均增益为11.0%，在图表任务上的平均增益为6.8%。我们深入分析了不同视觉编辑的效果，并解释了为什么ReFocus能够在不引入额外信息的情况下提高性能。此外，我们使用ReFocus收集了一个包含14,000个样本的训练集，并证明这种带有中间信息的视觉链式思考比标准的VQA数据提供了更好的监督，相较于使用问答对训练的模型，平均增益为8.0%，相较于CoT则为2.6%。
2501.05366	 | Search-o1: Agentic Search-Enhanced Large Reasoning Models	 | Xiaoxi Li,Guanting Dong,Jiajie Jin,Yuyao Zhang,Yujia Zhou,Yutao Zhu,Peitian Zhang,Zhicheng Dou	 | Search-o1 是一种通过结合代理检索增强生成（RAG）机制和 Reason-in-Documents 模块来提升大型推理模型（LRMs）的长距离推理能力的框架，使其在面对知识不足时能够动态检索和细化外部知识。实验表明，Search-o1 在多个复杂推理任务和问答基准测试中表现优异，显著提高了 LRMs 的可靠性和适用性。	 | Large reasoning models (LRMs) like OpenAI-o1 have demonstrated impressive long stepwise reasoning capabilities through large-scale reinforcement learning. However, their extended reasoning processes often suffer from knowledge insufficiency, leading to frequent uncertainties and potential errors. To address this limitation, we introduce \textbf{Search-o1}, a framework that enhances LRMs with an agentic retrieval-augmented generation (RAG) mechanism and a Reason-in-Documents module for refining retrieved documents. Search-o1 integrates an agentic search workflow into the reasoning process, enabling dynamic retrieval of external knowledge when LRMs encounter uncertain knowledge points. Additionally, due to the verbose nature of retrieved documents, we design a separate Reason-in-Documents module to deeply analyze the retrieved information before injecting it into the reasoning chain, minimizing noise and preserving coherent reasoning flow. Extensive experiments on complex reasoning tasks in science, mathematics, and coding, as well as six open-domain QA benchmarks, demonstrate the strong performance of Search-o1. This approach enhances the trustworthiness and applicability of LRMs in complex reasoning tasks, paving the way for more reliable and versatile intelligent systems. The code is available at \url{https://github.com/sunnynexus/Search-o1}.	 | 大型推理模型（LRMs）如OpenAI-o1 通过大规模强化学习展示了令人印象深刻的长步推理能力。然而，它们的延伸推理过程往往因知识不足而受到影响，导致频繁的不确定性和潜在的错误。为了克服这一局限，我们提出了**Search-o1**，一种框架，它通过引入代理检索增强生成（RAG）机制和用于细化检索文档的Reason-in-Documents模块来增强LRMs。Search-o1 将代理搜索工作流整合到推理过程中，使得当LRMs遇到不确定的知识点时能够动态检索外部知识。此外，由于检索到的文档通常内容冗长，我们设计了一个单独的Reason-in-Documents模块，在将这些信息注入推理链之前对其进行深入分析，从而减少噪声并保持连贯的推理流程。在科学、数学和编码等复杂推理任务以及六个开放领域问答基准测试中进行的广泛实验表明，Search-o1表现出色。此方法增强了LRMs在复杂推理任务中的可靠性和适用性，为更可靠和多功能的智能系统铺平了道路。代码可在 \url{https://github.com/sunnynexus/Search-o1} 获取。
2501.05255	 | CallNavi: A Study and Challenge on Function Calling Routing and Invocation in Large Language Models	 | Yewei Song,Cedric Lothritz,Xunzhu Tang,Saad Ezzini,Jacques Klein,Tegawendé F. Bissyandé,Andrey Boytsov,Ulrick Ble,Anne Goujon	 | 本文旨在解决聊天机器人在与软件系统交互时的挑战，特别是API调用的顺序和参数生成问题，通过构建新数据集评估模型性能，并提出了一种结合大规模语言模型和参数微调的增强API路由方法。	 | Interacting with a software system via a chatbot can be challenging, especially when the chatbot needs to generate API calls, in the right order and with the right parameters, to communicate with the system. API calling in chatbot systems poses significant challenges, particularly in complex, multi-step tasks requiring accurate API selection and execution. We contribute to this domain in three ways: first, by introducing a novel dataset designed to assess models on API function selection, parameter generation, and nested API calls; second, by benchmarking state-of-the-art language models across varying levels of complexity to evaluate their performance in API function generation and parameter accuracy; and third, by proposing an enhanced API routing method that combines general-purpose large language models for API selection with fine-tuned models for parameter generation and some prompt engineering approach. These approaches lead to substantial improvements in handling complex API tasks, offering practical advancements for real-world API-driven chatbot systems.	 | 通过聊天机器人与软件系统交互可能充满挑战，尤其是在聊天机器人需要按正确顺序生成带有正确参数的API调用来与系统通信时。在聊天机器人系统中进行API调用提出了重大挑战，尤其是在需要准确选择和执行多步任务中的API时。我们在这个领域做出了三方面的贡献：首先，我们引入了一个新颖的数据集，用于评估模型在API函数选择、参数生成和嵌套API调用方面的能力；其次，我们对最先进的语言模型进行了基准测试，以评估其在API函数生成和参数准确性方面的表现；最后，我们提出了一种增强的API路由方法，该方法结合了一般用途的大规模语言模型进行API选择，并对参数生成进行了微调，同时采用了一些提示工程技术。这些方法在处理复杂的API任务方面取得了显著改进，为实际的API驱动聊天机器人系统提供了实用的进步。
2501.05220	 | A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education	 | Ziqing Li,Mutlu Cukurova,Sahan Bulathwela	 | 本文介绍了一种主题控制问题生成（T-CQG）方法，通过在T5-small模型上进行微调并使用定制化数据集，增强了生成内容的相关性和教育有效性，结果表明该模型能够有效减轻教师的工作负担并支持个性化辅导系统。	 | The development of Automatic Question Generation (QG) models has the potential to significantly improve educational practices by reducing the teacher workload associated with creating educational content. This paper introduces a novel approach to educational question generation that controls the topical focus of questions. The proposed Topic-Controlled Question Generation (T-CQG) method enhances the relevance and effectiveness of the generated content for educational purposes. Our approach uses fine-tuning on a pre-trained T5-small model, employing specially created datasets tailored to educational needs. The research further explores the impacts of pre-training strategies, quantisation, and data augmentation on the model's performance. We specifically address the challenge of generating semantically aligned questions with paragraph-level contexts, thereby improving the topic specificity of the generated questions. In addition, we introduce and explore novel evaluation methods to assess the topical relatedness of the generated questions. Our results, validated through rigorous offline and human-backed evaluations, demonstrate that the proposed models effectively generate high-quality, topic-focused questions. These models have the potential to reduce teacher workload and support personalised tutoring systems by serving as bespoke question generators. With its relatively small number of parameters, the proposals not only advance the capabilities of question generation models for handling specific educational topics but also offer a scalable solution that reduces infrastructure costs. This scalability makes them feasible for widespread use in education without reliance on proprietary large language models like ChatGPT.	 | 自动问题生成（QG）模型的发展有潜力显著改善教育实践，减轻教师创建教育资源的工作负担。本文介绍了一种新颖的教育问题生成方法，该方法控制问题的主题聚焦。所提出的主题控制问题生成（T-CQG）方法增强了生成内容的相关性和教育有效性。我们的方法通过在预训练的T5-small模型上进行微调，并使用特别为教育需求量身定制的数据集，来实现这一目标。研究进一步探讨了预训练策略、量化和数据增强对模型性能的影响。我们特别解决了生成语义对齐的问题，使问题与段落级上下文对齐，从而提高生成问题的专题特异性。此外，我们引入并探讨了新的评估方法，以评估生成问题的主题相关性。通过严格的离线和人工验证评估，我们的结果表明，所提出的模型能够有效生成高质量的主题导向问题。这些模型有可能减轻教师的工作负担，并支持个性化辅导系统。由于参数较少，这些提案不仅推进了处理特定教育主题的问题生成模型的能力，而且还提供了一种可扩展的解决方案，能够降低基础设施成本。这种可扩展性使得它们在教育领域广泛应用成为可能，而无需依赖ChatGPT等专有大型语言模型。
2501.05165	 | Bringing Order Amidst Chaos: On the Role of Artificial Intelligence in Secure Software Engineering	 | Matteo Esposito	 | 本文旨在通过解决领域特定差异来提升安全软件工程中的AI准确性，并采用混合实证策略评估静态应用安全测试工具、进行方法级别分析，最终提高了缺陷预测的准确性；该研究强调了利用上下文知识对于提高漏洞和缺陷预测的重要性，为SSE领域的研究与实践提供了有益的见解。	 | Context. Developing secure and reliable software remains a key challenge in software engineering (SE). The ever-evolving technological landscape offers both opportunities and threats, creating a dynamic space where chaos and order compete. Secure software engineering (SSE) must continuously address vulnerabilities that endanger software systems and carry broader socio-economic risks, such as compromising critical national infrastructure and causing significant financial losses. Researchers and practitioners have explored methodologies like Static Application Security Testing Tools (SASTTs) and artificial intelligence (AI) approaches, including machine learning (ML) and large language models (LLMs), to detect and mitigate these vulnerabilities. Each method has unique strengths and limitations.   Aim. This thesis seeks to bring order to the chaos in SSE by addressing domain-specific differences that impact AI accuracy.   Methodology. The research employs a mix of empirical strategies, such as evaluating effort-aware metrics, analyzing SASTTs, conducting method-level analysis, and leveraging evidence-based techniques like systematic dataset reviews. These approaches help characterize vulnerability prediction datasets.   Results. Key findings include limitations in static analysis tools for identifying vulnerabilities, gaps in SASTT coverage of vulnerability types, weak relationships among vulnerability severity scores, improved defect prediction accuracy using just-in-time modeling, and threats posed by untouched methods.   Conclusions. This thesis highlights the complexity of SSE and the importance of contextual knowledge in improving AI-driven vulnerability and defect prediction. The comprehensive analysis advances effective prediction models, benefiting both researchers and practitioners.	 | 背景。在软件工程（SE）中，开发安全可靠的软件仍然是一个关键挑战。不断变化的技术环境既带来了机遇也带来了威胁，创造了一个动态的空间，在这个空间中，混沌与秩序相互竞争。安全软件工程（SSE）必须不断应对威胁软件系统的漏洞，这些漏洞还带来了更广泛的社会经济风险，例如破坏关键的国家基础设施，导致巨大的经济损失。研究人员和实践者已经探索了诸如静态应用安全测试工具（SASTTs）和人工智能（AI）方法，包括机器学习（ML）和大语言模型（LLMs），以检测和缓解这些漏洞。每种方法都有其独特的优势和局限性。  目标。本论文旨在通过解决影响AI准确性的领域特定差异来为SSE中的混乱带来秩序。  方法。研究采用了混合实证策略，包括评估工作量感知度量、分析SASTTs、进行方法级别分析，并利用基于证据的技术，如系统数据集审查。这些方法有助于描述漏洞预测数据集的特征。  结果。主要发现包括静态分析工具在识别漏洞方面的局限性、SASTT对漏洞类型的覆盖不足、脆弱性严重性评分之间关系较弱、使用即时建模提高了缺陷预测准确性以及未处理方法带来的威胁。  结论。本论文突出了SSE的复杂性以及在提高AI驱动的漏洞和缺陷预测方面利用上下文知识的重要性。全面的分析推进了有效的预测模型，这对研究人员和实践者都有益处。
2501.05082	 | Comparison of Feature Learning Methods for Metadata Extraction from PDF Scholarly Documents	 | Zeyd Boukhers,Cong Yang	 | 该研究评估了多种特征学习和预测方法，旨在从具有高模板差异的科学文献中提取元数据，以提高文献的可访问性和促进更广泛的使用。通过实验分析这些方法的准确性和效率，并探讨其优缺点，为未来研究提供指导。	 | The availability of metadata for scientific documents is pivotal in propelling scientific knowledge forward and for adhering to the FAIR principles (i.e. Findability, Accessibility, Interoperability, and Reusability) of research findings. However, the lack of sufficient metadata in published documents, particularly those from smaller and mid-sized publishers, hinders their accessibility. This issue is widespread in some disciplines, such as the German Social Sciences, where publications often employ diverse templates. To address this challenge, our study evaluates various feature learning and prediction methods, including natural language processing (NLP), computer vision (CV), and multimodal approaches, for extracting metadata from documents with high template variance. We aim to improve the accessibility of scientific documents and facilitate their wider use. To support our comparison of these methods, we provide comprehensive experimental results, analyzing their accuracy and efficiency in extracting metadata. Additionally, we provide valuable insights into the strengths and weaknesses of various feature learning and prediction methods, which can guide future research in this field.	 | 科学文献元数据的可用性对于推动科学知识的发展以及遵守研究发现的FAIR原则（即可查找性、可访问性、可互操作性和可重用性）至关重要。然而，特别是在较小和中型出版商的文献中，元数据的不足限制了这些文献的可访问性。这一问题在一些学科中尤为普遍，例如德国社会科学领域，其中出版物经常采用多种不同的模板。为应对这一挑战，我们的研究评估了多种特征学习和预测方法，包括自然语言处理（NLP）、计算机视觉（CV）和多模态方法，以从具有高模板差异的文档中提取元数据。我们的目标是提高科学文献的可访问性，并促进其更广泛的使用。为了支持这些方法的比较，我们提供了全面的实验结果，分析了它们在提取元数据方面的准确性和效率。此外，我们还提供了各种特征学习和预测方法的优点和缺点的宝贵见解，这可以为该领域的未来研究提供指导。
2501.04931	 | Jailbreaking Multimodal Large Language Models via Shuffle Inconsistency	 | Shiji Zhao,Ranjie Duan,Fengxiang Wang,Chi Chen,Caixin Kang,Jialing Tao,YueFeng Chen,Hui Xue,Xingxing Wei	 | 该研究发现多模态大语言模型在理解能力与安全能力之间存在不一致性，并提出了一种名为SI-Attack的新型文本-图像囚笼攻击方法，显著提高了对商业MLLMs的攻击成功率，特别是针对如GPT-4或Claude-3.5-Sonnet等模型。	 | Multimodal Large Language Models (MLLMs) have achieved impressive performance and have been put into practical use in commercial applications, but they still have potential safety mechanism vulnerabilities. Jailbreak attacks are red teaming methods that aim to bypass safety mechanisms and discover MLLMs' potential risks. Existing MLLMs' jailbreak methods often bypass the model's safety mechanism through complex optimization methods or carefully designed image and text prompts. Despite achieving some progress, they have a low attack success rate on commercial closed-source MLLMs. Unlike previous research, we empirically find that there exists a Shuffle Inconsistency between MLLMs' comprehension ability and safety ability for the shuffled harmful instruction. That is, from the perspective of comprehension ability, MLLMs can understand the shuffled harmful text-image instructions well. However, they can be easily bypassed by the shuffled harmful instructions from the perspective of safety ability, leading to harmful responses. Then we innovatively propose a text-image jailbreak attack named SI-Attack. Specifically, to fully utilize the Shuffle Inconsistency and overcome the shuffle randomness, we apply a query-based black-box optimization method to select the most harmful shuffled inputs based on the feedback of the toxic judge model. A series of experiments show that SI-Attack can improve the attack's performance on three benchmarks. In particular, SI-Attack can obviously improve the attack success rate for commercial MLLMs such as GPT-4o or Claude-3.5-Sonnet.	 | 多模态大语言模型（MLLMs）在商业应用中取得了显著的性能，并被实际使用，但它们仍然存在潜在的安全机制漏洞。红队技术中的囚笼攻击方法旨在绕过这些安全机制并发现MLLMs的潜在风险。现有的MLLMs囚笼攻击方法通常通过复杂的优化方法或精心设计的图像和文本提示来绕过模型的安全机制。尽管取得了一些进展，但它们在商业闭源的MLLMs中的攻击成功率较低。与以往研究不同，我们通过实证研究发现，MLLMs的理解能力和安全能力之间存在洗牌不一致性。即，在理解能力方面，MLLMs能够很好地理解打乱的有害指令文本-图像。然而，从安全能力的角度来看，它们可以通过打乱的有害指令轻易被绕过，从而导致有害响应。然后，我们创新地提出了一种名为SI-Attack的文本-图像囚笼攻击方法。具体来说，为了充分利用洗牌不一致性并克服洗牌的随机性，我们应用基于查询的黑盒优化方法，根据有害裁判模型的反馈选择最具危害性的打乱输入。一系列实验表明，SI-Attack可以在三个基准测试中提升攻击性能。特别地，SI-Attack可以明显提高商业MLLMs（如GPT-4o或Claude-3.5-Sonnet）的攻击成功率。
2501.04926	 | FLowHigh: Towards Efficient and High-Quality Audio Super-Resolution with Single-Step Flow Matching	 | Jun-Hak Yun,Seung-Bin Kim,Seong-Whan Lee	 | FLowHigh是一种将流匹配技术应用于音频超分辨率的新方法，能够在保持计算效率的同时生成高保真、高分辨率的音频，且在VCTK基准数据集上达到了最先进的性能。	 | Audio super-resolution is challenging owing to its ill-posed nature. Recently, the application of diffusion models in audio super-resolution has shown promising results in alleviating this challenge. However, diffusion-based models have limitations, primarily the necessity for numerous sampling steps, which causes significantly increased latency when synthesizing high-quality audio samples. In this paper, we propose FLowHigh, a novel approach that integrates flow matching, a highly efficient generative model, into audio super-resolution. We also explore probability paths specially tailored for audio super-resolution, which effectively capture high-resolution audio distributions, thereby enhancing reconstruction quality. The proposed method generates high-fidelity, high-resolution audio through a single-step sampling process across various input sampling rates. The experimental results on the VCTK benchmark dataset demonstrate that FLowHigh achieves state-of-the-art performance in audio super-resolution, as evaluated by log-spectral distance and ViSQOL while maintaining computational efficiency with only a single-step sampling process.	 | 音频超分辨率是一个具有挑战性的问题，主要是由于其病态性质。最近，将扩散模型应用于音频超分辨率中已经在缓解这一挑战方面显示出有前途的结果。然而，基于扩散的模型存在局限性，主要是需要大量采样步骤，这在合成高质量音频样本时会导致显著增加的延迟。在本文中，我们提出了一种名为FLowHigh的新方法，该方法将一种高效生成模型中的流匹配技术整合到音频超分辨率中。我们还探索了专门针对音频超分辨率的概率路径，这些路径能够有效捕捉高分辨率音频分布，从而提高重建质量。所提出的方法通过跨多种输入采样率的一次采样过程生成高保真、高分辨率的音频。在VCTK基准数据集上的实验结果表明，FLowHigh在音频超分辨率方面达到了最先进的性能，根据对数谱距离和ViSQOL评估，同时仅通过一次采样过程保持了计算效率。
2501.04844	 | Enhancing Listened Speech Decoding from EEG via Parallel Phoneme Sequence Prediction	 | Jihwan Lee,Tiantian Feng,Aditya Kommineni,Sudarsana Reddy Kadiri,Shrikanth Narayanan	 | 该研究提出了一种新颖的脑-计算机接口方法，通过结合EEG信号、生成语音波形和音素预测器来同时解码所听语音的文本音素序列，提升了对言语感知受损人群的帮助，并在两种模态下均优于现有方法。	 | Brain-computer interfaces (BCI) offer numerous human-centered application possibilities, particularly affecting people with neurological disorders. Text or speech decoding from brain activities is a relevant domain that could augment the quality of life for people with impaired speech perception. We propose a novel approach to enhance listened speech decoding from electroencephalography (EEG) signals by utilizing an auxiliary phoneme predictor that simultaneously decodes textual phoneme sequences. The proposed model architecture consists of three main parts: EEG module, speech module, and phoneme predictor. The EEG module learns to properly represent EEG signals into EEG embeddings. The speech module generates speech waveforms from the EEG embeddings. The phoneme predictor outputs the decoded phoneme sequences in text modality. Our proposed approach allows users to obtain decoded listened speech from EEG signals in both modalities (speech waveforms and textual phoneme sequences) simultaneously, eliminating the need for a concatenated sequential pipeline for each modality. The proposed approach also outperforms previous methods in both modalities. The source code and speech samples are publicly available.	 | 脑-计算机接口（BCI）提供了众多以人为中心的应用可能性，特别是在影响神经疾病患者方面。从大脑活动解码文本或语音是相关领域，可以提升言语感知受损人群的生活质量。我们提出了一种新颖的方法，通过利用辅助音素预测器来增强从脑电图（EEG）信号解码所听语音的能力，该预测器同时解码文本音素序列。我们提出的模型架构包含三个主要部分：EEG模块、语音模块和音素预测器。EEG模块学习将EEG信号正确地表示为EEG嵌入。语音模块从EEG嵌入生成语音波形。音素预测器输出文本模态下的解码音素序列。我们提出的方法允许用户同时从两种模态（语音波形和文本音素序列）获得从EEG信号解码的所听语音，从而消除了为每个模态构建连接顺序流水线的需要。此外，我们提出的方法在两种模态下均优于先前方法。源代码和语音样本已公开。
2501.04820	 | Unifying the Extremes: Developing a Unified Model for Detecting and Predicting Extremist Traits and Radicalization	 | Allison Lahnala,Vasudha Varadarajan,Lucie Flek,H. Andrew Schwartz,Ryan L. Boyd	 | 本文提出了一种新颖的方法，通过分析社交媒体上的言语行为特征来量化极端主义程度，并构建了一个包含11个因素的“极端主义十一项”模型，该模型能够准确描述不同意识形态在线社区的极端主义水平，并预测用户加入极端主义论坛的时间。	 | The proliferation of ideological movements into extremist factions via social media has become a global concern. While radicalization has been studied extensively within the context of specific ideologies, our ability to accurately characterize extremism in more generalizable terms remains underdeveloped. In this paper, we propose a novel method for extracting and analyzing extremist discourse across a range of online community forums. By focusing on verbal behavioral signatures of extremist traits, we develop a framework for quantifying extremism at both user and community levels. Our research identifies 11 distinct factors, which we term ``The Extremist Eleven,'' as a generalized psychosocial model of extremism. Applying our method to various online communities, we demonstrate an ability to characterize ideologically diverse communities across the 11 extremist traits. We demonstrate the power of this method by analyzing user histories from members of the incel community. We find that our framework accurately predicts which users join the incel community up to 10 months before their actual entry with an AUC of $>0.6$, steadily increasing to AUC ~0.9 three to four months before the event. Further, we find that upon entry into an extremist forum, the users tend to maintain their level of extremism within the community, while still remaining distinguishable from the general online discourse. Our findings contribute to the study of extremism by introducing a more holistic, cross-ideological approach that transcends traditional, trait-specific models.	 | 随着极化思想运动通过社交媒体发展成为极端主义派别，这一问题已成为全球关注的焦点。虽然对特定意识形态中的极化过程进行了广泛研究，但我们以更具普适性的方式准确描述极端主义的能力仍然不足。在本文中，我们提出了一种新颖的方法，用于跨多种在线社区论坛提取和分析极端主义言论。通过关注极端主义特质的言语行为特征，我们开发了一个框架，以量化极端主义在用户和个人社区层面的程度。我们的研究确定了11个不同的因素，我们将其称为“极端主义十一项”，作为极端主义的一般心理社会模型。将我们的方法应用于各种在线社区，我们能够通过11项极端主义特质来表征具有不同意识形态特征的社区。我们通过分析“ incel”社区成员的历史记录展示了该方法的力量。我们发现，我们的框架可以准确预测用户在实际加入“ incel”社区前10个月加入该社区的情况，AUC值大于0.6，并且在事件发生前三到四个月时AUC值达到约0.9。此外，我们发现，用户进入极端主义论坛后，其在社区内的极端主义程度保持稳定，但仍与一般网络言论明显不同。我们的研究结果通过提供一种更全面、跨意识形态的方法，超越了传统的、特定于特质的模型，为极端主义研究做出了贡献。
2501.04802	 | Reproducing HotFlip for Corpus Poisoning Attacks in Dense Retrieval	 | Yongkang Li,Panagiotis Eustratiadis,Evangelos Kanoulas	 | HotFlip是一种基于 topical 梯度的单词替换方法，用于攻击语言模型和检索系统，但其生成对抗性段落的过程耗时较长且依赖于用户查询假设。本文通过优化提高了HotFlip的效率，将对抗性生成过程时间从4小时缩短至15分钟，并在多种攻击任务中验证了其有效性和性能变化。	 | HotFlip is a topical gradient-based word substitution method for attacking language models. Recently, this method has been further applied to attack retrieval systems by generating malicious passages that are injected into a corpus, i.e., corpus poisoning. However, HotFlip is known to be computationally inefficient, with the majority of time being spent on gradient accumulation for each query-passage pair during the adversarial token generation phase, making it impossible to generate an adequate number of adversarial passages in a reasonable amount of time. Moreover, the attack method itself assumes access to a set of user queries, a strong assumption that does not correspond to how real-world adversarial attacks are usually performed. In this paper, we first significantly boost the efficiency of HotFlip, reducing the adversarial generation process from 4 hours per document to only 15 minutes, using the same hardware. We further contribute experiments and analysis on two additional tasks: (1) transfer-based black-box attacks, and (2) query-agnostic attacks. Whenever possible, we provide comparisons between the original method and our improved version. Our experiments demonstrate that HotFlip can effectively attack a variety of dense retrievers, with an observed trend that its attack performance diminishes against more advanced and recent methods. Interestingly, we observe that while HotFlip performs poorly in a black-box setting, indicating limited capacity for generalization, in query-agnostic scenarios its performance is correlated to the volume of injected adversarial passages.	 | HotFlip是一种基于 topical 梯度的单词替换方法，用于攻击语言模型。最近，这种方法进一步被应用于攻击检索系统，通过生成恶意段落并注入到语料库中，即语料库中毒。然而，HotFlip 知道在对抗性标记生成阶段，大部分时间都花费在每个查询-段落对的梯度累积上，这使得在合理的时间内生成足够的对抗性段落变得不可能。此外，攻击方法本身假设可以访问一组用户查询，这是一个很强的假设，与实际世界的对抗性攻击通常是如何进行的不符。在本文中，我们首先大幅提高了HotFlip的效率，将对抗性生成过程从每份文档4小时缩短到仅15分钟，使用相同的硬件。我们还进一步在两个额外的任务上进行实验和分析：（1）基于转移的黑盒攻击；（2）查询无感知攻击。每有机会，我们都提供了原始方法与改进版本之间的比较。我们的实验表明，HotFlip能够有效攻击各种密集检索器，观察到的趋势是，它的攻击性能在对抗更高级和更近期的方法时会下降。有趣的是，我们观察到，在黑盒设置下，HotFlip表现较差，这表明其泛化能力有限；而在查询无感知场景下，其性能与注入的对抗性段落数量相关。
